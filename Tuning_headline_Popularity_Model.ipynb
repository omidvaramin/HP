{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f110f4e2",
   "metadata": {},
   "source": [
    "## Contents <a id='home'></a>\n",
    "## [1. Data Preprocessing](#dp)\n",
    "## [2. Fine Tuning ](#ftb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c2d5989",
   "metadata": {},
   "source": [
    "The following code is used to fine-tune a transformer encoder model on headline popularity dataset.\n",
    "For further information, please look at subsection III-C ([link](https://ieeexplore.ieee.org/abstract/document/10154027))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7424ca0f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\" #specify which GPU to use if you have multiple GPUs\n",
    "import torch\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AdamW, get_linear_schedule_with_warmup\n",
    "from torch.utils.data import TensorDataset, random_split, DataLoader, SequentialSampler\n",
    "import numpy as np\n",
    "import time\n",
    "import datetime\n",
    "import random\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import shutil\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d225c499",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# If there's a GPU available...\n",
    "if torch.cuda.is_available():    \n",
    "\n",
    "    # Tell PyTorch to use the GPU.    \n",
    "    device = torch.device(\"cuda\")\n",
    "\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "\n",
    "# If not...\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "device = torch.device('cuda:0')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b19db165",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DATA_PATH = '/local/data1/users/omidvar/HG/twitter/HQG5/Twitter/ProcessedData/split/train.feather'\n",
    "TEST_DATA_PATH = '/local/data1/users/omidvar/HG/twitter/HQG5/Twitter/ProcessedData/split/test.feather'\n",
    "VALID_DATA_PATH = '/local/data1/users/omidvar/HG/twitter/HQG5/Twitter/ProcessedData/split/valid.feather'\n",
    "MODEL_PATH = './HP_models'\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "MODEL_NAME = 'sentence-transformers/all-mpnet-base-v2'\n",
    "\n",
    "EPOCHS = 20\n",
    "SEED_VALUE = 42 # Set the seed value all over the place to make this reproducible.\n",
    "PRINT_PARAMS = True # If you are interested you can keep it True to print the training parameters of the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "568e1f31",
   "metadata": {},
   "source": [
    "# 3. Data Preprocessing <a id='dp'></a>\n",
    "[home](#home)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d73a34b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_train = pd.read_feather(TRAIN_DATA_PATH)\n",
    "df_test = pd.read_feather(TEST_DATA_PATH)\n",
    "df_valid = pd.read_feather(VALID_DATA_PATH)\n",
    "\n",
    "print(f'Length of the training data = {str(len(df_train))}')\n",
    "print(f'Length of the test data = {str(len(df_test))}')\n",
    "print(f'Length of the valid data = {str(len(df_valid))}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "575d6e06",
   "metadata": {},
   "source": [
    "## 3.1 Tokenizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f83f3cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17826b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_raw_data(df_data):\n",
    "    sentences = df_data.post_text1.values\n",
    "    labels = df_data.q9_favorite_count_norm.values\n",
    "    labels = [float(l) for l in labels]\n",
    "    return sentences, labels\n",
    "\n",
    "#tokenize data\n",
    "def tokenizer_all(sentences):\n",
    "    input_ids = []\n",
    "    attention_masks = []\n",
    "    for sent in sentences:\n",
    "        encoded_input = tokenizer.encode_plus(\n",
    "                                sent,\n",
    "                                add_special_tokens= True,\n",
    "                                max_length= 52,\n",
    "                                pad_to_max_length=True,\n",
    "                                return_attention_mask= True,\n",
    "                                return_tensors = 'pt')\n",
    "\n",
    "        input_ids.append(encoded_input['input_ids'])\n",
    "\n",
    "\n",
    "        attention_masks.append(encoded_input['attention_mask'])\n",
    "    return input_ids, attention_masks\n",
    "\n",
    "def list2tensor(input_ids, attention_masks, labels):\n",
    "    input_ids = torch.cat(input_ids, dim=0)\n",
    "    attention_masks = torch.cat(attention_masks, dim=0)\n",
    "    labels = torch.tensor(labels)\n",
    "    return input_ids, attention_masks, labels\n",
    "\n",
    "\n",
    "def prepare_data(df_data):\n",
    "    sentences, labels = get_raw_data(df_data)\n",
    "    input_ids, attention_masks = tokenizer_all(sentences)\n",
    "    input_ids, attention_masks, labels = list2tensor(input_ids, attention_masks, labels)\n",
    "    dataset=  TensorDataset(input_ids, attention_masks, labels)\n",
    "    train_dataloader = DataLoader(\n",
    "            dataset,  # The training samples.\n",
    "            sampler = SequentialSampler(dataset),\n",
    "            batch_size = BATCH_SIZE # Trains with this batch size.\n",
    "    \n",
    "        )\n",
    "    return train_dataloader, dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa236a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader, train_dataset = prepare_data(df_data=df_train)\n",
    "test_dataloader, test_dataset = prepare_data(df_data=df_test)\n",
    "valid_dataloader, valid_dataset = prepare_data(df_data=df_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d639e76f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dcd3d11c",
   "metadata": {},
   "source": [
    "# 4. Fine Tuning Headline Popularity Prediction Model <a id = 'ftb'></a>\n",
    "[home](#home)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08bc3a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load BertForSequenceClassification, the pretrained BERT model with a single linear classification layer on top. \n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    MODEL_NAME, # We use the 12-layer BERT model, with an uncased vocab.\n",
    "    num_labels = 1, # The number of output labels--1 for regression.   \n",
    "    output_attentions = False, # Whether the model returns attentions weights.\n",
    "    output_hidden_states = False, # Whether the model returns all hidden-states.\n",
    "    #cache_dir= '/local/data1/omidvar/codes/HG/transformercashe'\n",
    ")\n",
    "\n",
    "# move the model to GPU\n",
    "model.cuda(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e76fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# We are interested in printing the parameters of the model\n",
    "def print_params(model):\n",
    "    params = list(model.named_parameters())\n",
    "\n",
    "    print('The BERT model has {:} different named parameters.\\n'.format(len(params)))\n",
    "\n",
    "    print('==== Embedding Layer ====\\n')\n",
    "\n",
    "    for p in params[0:5]:\n",
    "        print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
    "\n",
    "    print('\\n==== First Transformer ====\\n')\n",
    "\n",
    "    for p in params[5:21]:\n",
    "        print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
    "\n",
    "    print('\\n==== Output Layer ====\\n')\n",
    "\n",
    "    for p in params[-4:]:\n",
    "        print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
    "\n",
    "if PRINT_PARAMS:\n",
    "    print_params(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84cb2ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = AdamW(model.parameters(),\n",
    "                  lr = 2e-5,\n",
    "                 eps = 1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6013552b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Total number of training steps is [number of batches] x [number of epochs]. \n",
    "total_steps = len(train_dataloader) * EPOCHS\n",
    "\n",
    "# Create the learning rate scheduler.\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps = 0, \n",
    "                                            num_training_steps = total_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "593ae292",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_squared(preds, labels):\n",
    "    return mean_squared_error(labels, preds)\n",
    "\n",
    "def format_time(elapsed):\n",
    "    '''\n",
    "    Takes a time in seconds and returns a string hh:mm:ss\n",
    "    '''\n",
    "    # Round to the nearest second.\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    \n",
    "    # Format as hh:mm:ss\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))\n",
    "\n",
    "def eval_model(model, dataloader, verbose=True):\n",
    "    t0 = time.time()\n",
    "    model.eval()\n",
    "\n",
    "    # Tracking variables \n",
    "    total_accuracy = 0\n",
    "    total_loss = 0\n",
    "\n",
    "    for batch in dataloader:\n",
    "        # Unpack this training batch from our dataloader.\n",
    "        #   [0]: input ids \n",
    "        #   [1]: attention masks\n",
    "        #   [2]: labels  \n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "\n",
    "\n",
    "        with torch.no_grad():        \n",
    "            result = model(b_input_ids, \n",
    "                            attention_mask=b_input_mask,\n",
    "                            labels=b_labels,\n",
    "                            return_dict=True)\n",
    "            \n",
    "        # Get the loss and \"logits\" output by the model.\n",
    "        loss = result.loss\n",
    "        logits = result.logits\n",
    "\n",
    "        # Accumulate the validation loss.\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Move logits and labels to CPU\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "        # Calculate the accuracy for this batch \n",
    "        total_accuracy += mean_squared(logits, label_ids)\n",
    "\n",
    "    # Calculate final accuracy for the run\n",
    "    avg_accuracy = total_accuracy / len(valid_dataloader)\n",
    "    \n",
    "\n",
    "    # Calculate the average loss over all of the batches.\n",
    "    avg_loss = total_loss / len(valid_dataloader)\n",
    "\n",
    "    \n",
    "    validation_time = format_time(time.time() - t0)\n",
    "\n",
    "    if verbose:\n",
    "        print(\"  Accuracy: {0:.2f}\".format(avg_accuracy))\n",
    "        print(\"  Average Validation Loss: {}\".format(avg_loss))\n",
    "\n",
    "    return avg_accuracy, avg_loss, validation_time\n",
    "\n",
    "\n",
    "def make_dir(path):\n",
    "    if os.path.exists(path):\n",
    "        shutil.rmtree(path)\n",
    "    os.makedirs(path)\n",
    "\n",
    "def save_model(model, path, epoch):\n",
    "    path = os.path.join(path, str(epoch))\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "    model.save_pretrained(path)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b896cc39",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# This training code is based on the `run_glue.py` script here:\n",
    "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
    "\n",
    "\n",
    "random.seed(SEED_VALUE)\n",
    "np.random.seed(SEED_VALUE)\n",
    "torch.manual_seed(SEED_VALUE)\n",
    "torch.cuda.manual_seed_all(SEED_VALUE)\n",
    "\n",
    "training_stats = []\n",
    "\n",
    "# Measure the total training time for the whole run.\n",
    "total_t0 = time.time()\n",
    "\n",
    "make_dir(MODEL_PATH)\n",
    "\n",
    "all_batch_loss = []\n",
    "\n",
    "# For each epoch...\n",
    "for epoch_i in range(0, EPOCHS):\n",
    "    \n",
    "    total_eval_loss1 = 0\n",
    "    total_eval_accuracy1 = 0\n",
    "    \n",
    "    if epoch_i == 0: #initial evaluation to see how good the pretrained model is without training\n",
    "        avg_val_accuracy, avg_val_loss, _ = eval_model(model, valid_dataloader)\n",
    "\n",
    "\n",
    "    # ========================================\n",
    "    #               Training\n",
    "    # ========================================\n",
    "    \n",
    "    # Perform one full pass over the training set.\n",
    "\n",
    "    print(\"\")\n",
    "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, EPOCHS))\n",
    "    print('Training...')\n",
    "    \n",
    "    \n",
    "    #Save the model\n",
    "    if epoch_i != 0:\n",
    "        save_model(model,MODEL_PATH, epoch_i)\n",
    "    \n",
    "    \n",
    "    # Measure how long the training epoch takes.\n",
    "    t0 = time.time()\n",
    "\n",
    "    # Reset the total loss for this epoch.\n",
    "    total_train_loss = 0\n",
    "\n",
    "    # Put the model into training mode\n",
    "    model.train()\n",
    "\n",
    "    # For each batch of training data...\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "\n",
    "        \n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "\n",
    "        #Clearn previously calculated gradients\n",
    "        model.zero_grad()        \n",
    "\n",
    "        # Perform a forward pass \n",
    "        result = model(b_input_ids,  \n",
    "                       attention_mask=b_input_mask, \n",
    "                       labels=b_labels,\n",
    "                       return_dict=True)\n",
    "\n",
    "        loss = result.loss\n",
    "        logits = result.logits\n",
    "        \n",
    "        all_batch_loss.append([epoch_i, step, loss.item()])\n",
    "        \n",
    "        # Progress update every 40 batches.\n",
    "        if step % 40 == 0 and not step == 0:\n",
    "            # Calculate elapsed time in minutes.\n",
    "            elapsed = format_time(time.time() - t0)\n",
    "            \n",
    "            # Report progress.\n",
    "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.   loss:{}'.format(step, len(train_dataloader), elapsed,loss.item()))\n",
    "        \n",
    "        \n",
    "        # Accumulate the training loss over all of the batches\n",
    "        total_train_loss += loss.item()\n",
    "\n",
    "        # Perform a backward pass to calculate the gradients.\n",
    "        loss.backward()\n",
    "\n",
    "        # Clip the norm of the gradients to 1.0 (preventing exploding gradients problem)\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        # Update parameters \n",
    "        optimizer.step()\n",
    "\n",
    "        # Update the learning rate.\n",
    "        scheduler.step()\n",
    "\n",
    "    # Calculate the average loss over all of the batches.\n",
    "    avg_train_loss = total_train_loss / len(train_dataloader)            \n",
    "    \n",
    "    # Measure how long this epoch took.\n",
    "    training_time = format_time(time.time() - t0)\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"  Average training loss: {}\".format(avg_train_loss))\n",
    "    print(\"  Training epcoh took: {:}\".format(training_time))\n",
    "        \n",
    "    # ========================================\n",
    "    #               Validation\n",
    "    # ========================================\n",
    "    avg_val_accuracy, avg_val_loss, validation_time = eval_model(model, valid_dataloader)\n",
    "    \n",
    "    # Record all statistics from this epoch.\n",
    "    training_stats.append(\n",
    "        {\n",
    "            'epoch': epoch_i + 1,\n",
    "            'Training Loss': avg_train_loss,\n",
    "            'Valid. Loss': avg_val_loss,\n",
    "            'Valid. Accur.': avg_val_accuracy,\n",
    "            'Training Time': training_time,\n",
    "            'Validation Time': validation_time\n",
    "        }\n",
    "    )\n",
    "\n",
    "print(\"\")\n",
    "print(\"Training complete!\")\n",
    "\n",
    "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99500e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_dir(os.path.join(MODEL_PATH, \"Logs\"))\n",
    "\n",
    "with open(os.path.join(MODEL_PATH, \"Logs\", 'training_stats'), 'wb') as f:\n",
    "    pickle.dump(training_stats, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e4aba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create a DataFrame from our training statistics.\n",
    "df_stats = pd.DataFrame(data=training_stats)\n",
    "\n",
    "# Use the 'epoch' as the row index.\n",
    "df_stats = df_stats.set_index('epoch')\n",
    "\n",
    "df_stats.to_csv(os.path.join(MODEL_PATH, \"Logs\", 'training_stats.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5fcf81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use plot styling from seaborn.\n",
    "sns.set(style='darkgrid')\n",
    "\n",
    "# Increase the plot size and font size.\n",
    "sns.set(font_scale=0.5)\n",
    "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
    "\n",
    "# Plot the learning curve.\n",
    "plt.plot(df_stats['Training Loss'], 'b-o', label=\"Training\")\n",
    "plt.plot(df_stats['Valid. Loss'], 'g-o', label=\"Validation\")\n",
    "\n",
    "# Label the plot.\n",
    "plt.title(\"Training & Validation Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "\n",
    "xticks_list = []\n",
    "for i in range(len(training_stats)):\n",
    "    xticks_list.append(i+1)\n",
    "\n",
    "plt.xticks(xticks_list)\n",
    "\n",
    "plt.savefig( os.path.join(MODEL_PATH, \"Logs\", 'trainloss.jpg'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
